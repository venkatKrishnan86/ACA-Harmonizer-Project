{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T20:36:01.263591Z",
     "start_time": "2023-11-19T20:35:59.094962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "from utils import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'chunks_vocal',\n",
       " 'test',\n",
       " 'train_data.pt',\n",
       " 'test_data.pt',\n",
       " 'chunks_chord',\n",
       " 'model_train',\n",
       " 'train',\n",
       " 'model_test']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = '../../../../Music Technology/Datasets/musdb18hq/'\n",
    "os.listdir(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "HOP = 256\n",
    "FRAMES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (gru): GRU(12, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord_detector = GRU()\n",
    "chord_detector.load_state_dict(torch.load('./models/chord_detector.pth'))\n",
    "chord_detector.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, audio, chroma_req = True, chord_templates:dict = json.load(open('./chord_templates.json')), sr = SR, hop = HOP):\n",
    "    if chroma_req:\n",
    "        chroma = torch.Tensor(librosa.feature.chroma_cens(y=audio, sr = sr, hop_length=hop)).T.unsqueeze(0)\n",
    "    else:\n",
    "        chroma = audio\n",
    "    with torch.no_grad():\n",
    "        outputs = nn.functional.softmax(model(chroma), 1)[0]\n",
    "    min_val = 120\n",
    "    min_key = ''\n",
    "    for key, val in chord_templates.items():\n",
    "        out = torch.norm(torch.Tensor(val) - outputs)\n",
    "        if min_val >= out:\n",
    "            min_val = out\n",
    "            min_key = key\n",
    "    return min_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, chroma, frame = 6):\n",
    "    stack = []\n",
    "    time = []\n",
    "    model.eval()\n",
    "    pred = predict(model, chroma[:frame, :].unsqueeze(0), False)\n",
    "    prev_pred = pred\n",
    "    dur = 1\n",
    "    main_sub = 0\n",
    "    for i in tqdm(range(frame, chroma.shape[0]-frame+1, frame)):\n",
    "        model.eval()\n",
    "        pred = predict(model, chroma[i:i+frame, :].unsqueeze(0), False)\n",
    "        if(pred != prev_pred):\n",
    "            if(dur>10):\n",
    "                if(len(stack)==0):\n",
    "                    stack.append(prev_pred)\n",
    "                elif(stack[-1]==prev_pred):\n",
    "                    dur = 0\n",
    "                    prev_pred = pred\n",
    "                    continue\n",
    "                else:\n",
    "                    stack.append(prev_pred)\n",
    "                if len(time)!=0:\n",
    "                    time.append((i)*HOP/SR - main_sub)\n",
    "                else:\n",
    "                    main_sub = (i)*HOP/SR\n",
    "                    time.append(0.0)\n",
    "            dur = 0\n",
    "            prev_pred = pred\n",
    "        dur+=1\n",
    "    return stack, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!! Code in this cell is for chunking the dataset into little bits - you'll only need to run this once\n",
    "\n",
    "# \n",
    "\n",
    "# data_location = \"../../../../Music Technology/Datasets/musdb18hq/test/\"\n",
    "# out_location = \"../../../../Music Technology/Datasets/musdb18hq/\"\n",
    "# folders = os.listdir(data_location)\n",
    "# count = 0\n",
    "\n",
    "# # print(chord_templates[\"F#\"])\n",
    "\n",
    "# for folder in folders:\n",
    "#     if not os.path.isdir(data_location+folder):\n",
    "#         continue\n",
    "#     mixture_y, _ = librosa.load(data_location + '/' + folder + '/mixture.wav', sr=SR)\n",
    "#     vocals_y, _ = librosa.load(data_location + '/' + folder + '/vocals.wav', sr=SR)\n",
    "#     mixture_y = mixture_y/np.max(np.abs(mixture_y))\n",
    "#     vocals_y = vocals_y/np.max(np.abs(vocals_y))\n",
    "\n",
    "#     mixture_chroma = torch.Tensor(librosa.feature.chroma_cens(y=mixture_y, sr = SR, hop_length=HOP)).T\n",
    "#     # vocals_chroma = torch.Tensor(librosa.feature.chroma_cens(y=vocals_y, sr = SR, hop_length=HOP)).T\n",
    "#     chunk_length = FRAMES\n",
    "#     nchunks = mixture_chroma.shape[0] // chunk_length # no padding\n",
    "\n",
    "#     if not os.path.isdir(out_location+'chunks_chord_test/'):\n",
    "#         os.mkdir(out_location+'chunks_chord_test')\n",
    "#     if not os.path.isdir(out_location+'chunks_vocal_test/'):\n",
    "#         os.mkdir(out_location+'chunks_vocal_test')\n",
    "    \n",
    "#     # Get chords from mixture chroma\n",
    "#     chord_stack, time = prediction(chord_detector, mixture_chroma)\n",
    "#     frame_num = np.array([int(i/((HOP/SR)*6)) for i in time])\n",
    "#     chord_stack = np.array([frame_num, chord_stack]).T\n",
    "#     chords = []\n",
    "#     for prev, curr in zip(chord_stack[:-1], chord_stack[1:]):\n",
    "#         frame_diff = int(curr[0]) - int(prev[0])\n",
    "#         chords.extend([prev[1] for _ in range(frame_diff)])\n",
    "#     chords.extend([chord_stack[-1][1] for _ in range(nchunks - len(chords))])\n",
    "#     with open(out_location+\"chunks_chord_test/chord_\"+str(count), \"wb\") as fp:\n",
    "#         pickle.dump(chords, fp)\n",
    "#     print(len(chords), nchunks)\n",
    "#     sf.write(out_location + 'chunks_vocal_test/vocal_' + str(count)+'.wav', vocals_y, SR)\n",
    "    \n",
    "#     # for i in range(0, mixture_chroma.shape[0]-chunk_length+1,chunk_length):\n",
    "#     #     vocal_chunk = vocals_chroma[i:i+chunk_length,:]\n",
    "#     #     print(vocal_chunk.shape)\\\n",
    "#         # torch.save(vocal_chunk, out_location + 'chunks_vocal/vocal_' + str(count) + '_' + str(i//chunk_length) + '.pt')\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba0e9c51f9cdef1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T19:10:53.062313Z",
     "start_time": "2023-11-01T19:10:09.625541Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5708/5708 [00:08<00:00, 685.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5709 5709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7017/7017 [00:10<00:00, 668.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7018 7018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6351/6351 [00:09<00:00, 683.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6352 6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6361/6361 [00:09<00:00, 700.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6362 6362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6528/6528 [00:09<00:00, 691.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6529 6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5756/5756 [00:08<00:00, 686.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5757 5757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5898/5898 [00:08<00:00, 693.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5899 5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7683/7683 [00:11<00:00, 698.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7684 7684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7090/7090 [00:10<00:00, 704.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7091 7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8234/8234 [00:11<00:00, 696.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8235 8235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8776/8776 [00:12<00:00, 706.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8777 8777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9125/9125 [00:13<00:00, 698.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9126 9126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5092/5092 [00:07<00:00, 694.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5093 5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9108/9108 [00:12<00:00, 701.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9109 9109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7813/7813 [00:11<00:00, 701.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7814 7814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7267/7267 [00:10<00:00, 704.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7268 7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12355/12355 [00:17<00:00, 707.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12356 12356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6298/6298 [00:08<00:00, 701.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6299 6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6092/6092 [00:08<00:00, 701.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6093 6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7751/7751 [00:11<00:00, 691.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7752 7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6749/6749 [00:09<00:00, 715.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750 6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5048/5048 [00:07<00:00, 713.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5049 5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7264/7264 [00:10<00:00, 713.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7265 7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9675/9675 [00:13<00:00, 718.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9676 9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9195/9195 [00:13<00:00, 696.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9196 9196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6737/6737 [00:09<00:00, 697.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6738 6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6031/6031 [00:08<00:00, 704.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6032 6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9515/9515 [00:13<00:00, 705.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9516 9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7082/7082 [00:10<00:00, 701.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7083 7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5468/5468 [00:07<00:00, 696.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:11<00:00, 704.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7919 7919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8084/8084 [00:11<00:00, 700.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8085 8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6728/6728 [00:09<00:00, 695.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6729 6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4066/4066 [00:05<00:00, 688.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4067 4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7295/7295 [00:10<00:00, 703.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7296 7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8976/8976 [00:12<00:00, 706.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8977 8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6995/6995 [00:10<00:00, 698.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6996 6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11359/11359 [00:16<00:00, 709.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11360 11360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9867/9867 [00:13<00:00, 706.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9868 9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8406/8406 [00:11<00:00, 705.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8407 8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5155/5155 [00:07<00:00, 702.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5156 5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7317/7317 [00:10<00:00, 698.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7318 7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6319/6319 [00:09<00:00, 700.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6320 6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7183/7183 [00:10<00:00, 705.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7184 7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7208/7208 [00:10<00:00, 699.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7209 7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5968/5968 [00:08<00:00, 696.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5969 5969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5367/5367 [00:07<00:00, 692.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5368 5368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7854/7854 [00:10<00:00, 714.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7855 7855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4670/4670 [00:06<00:00, 720.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4671 4671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2186/2186 [00:03<00:00, 709.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2187 2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # !!! Code in this cell is for chunking the dataset into little bits - you'll only need to run this once\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# data_location = \"../../../../Music Technology/Datasets/musdb18hq/train/\"\n",
    "# out_location = \"../../../../Music Technology/Datasets/musdb18hq/\"\n",
    "# folders = os.listdir(data_location)\n",
    "# count = 0\n",
    "\n",
    "# # print(chord_templates[\"F#\"])\n",
    "\n",
    "# for folder in folders:\n",
    "#     if not os.path.isdir(data_location+folder):\n",
    "#         continue\n",
    "#     mixture_y, _ = librosa.load(data_location + '/' + folder + '/mixture.wav', sr=SR)\n",
    "#     vocals_y, _ = librosa.load(data_location + '/' + folder + '/vocals.wav', sr=SR)\n",
    "#     mixture_y = mixture_y/np.max(np.abs(mixture_y))\n",
    "#     vocals_y = vocals_y/np.max(np.abs(vocals_y))\n",
    "\n",
    "#     mixture_chroma = torch.Tensor(librosa.feature.chroma_cens(y=mixture_y, sr = SR, hop_length=HOP)).T\n",
    "#     # vocals_chroma = torch.Tensor(librosa.feature.chroma_cens(y=vocals_y, sr = SR, hop_length=HOP)).T\n",
    "#     chunk_length = FRAMES\n",
    "#     nchunks = mixture_chroma.shape[0] // chunk_length # no padding\n",
    "\n",
    "#     if not os.path.isdir(out_location+'chunks_chord/'):\n",
    "#         os.mkdir(out_location+'chunks_chord')\n",
    "#     if not os.path.isdir(out_location+'chunks_vocal/'):\n",
    "#         os.mkdir(out_location+'chunks_vocal')\n",
    "    \n",
    "#     # Get chords from mixture chroma\n",
    "#     chord_stack, time = prediction(chord_detector, mixture_chroma)\n",
    "#     frame_num = np.array([int(i/((HOP/SR)*6)) for i in time])\n",
    "#     chord_stack = np.array([frame_num, chord_stack]).T\n",
    "#     chords = []\n",
    "#     for prev, curr in zip(chord_stack[:-1], chord_stack[1:]):\n",
    "#         frame_diff = int(curr[0]) - int(prev[0])\n",
    "#         chords.extend([prev[1] for _ in range(frame_diff)])\n",
    "#     chords.extend([chord_stack[-1][1] for _ in range(nchunks - len(chords))])\n",
    "#     with open(out_location+\"chunks_chord/chord_\"+str(count), \"wb\") as fp:\n",
    "#         pickle.dump(chords, fp)\n",
    "#     print(len(chords), nchunks)\n",
    "#     sf.write(out_location + 'chunks_vocal/vocal_' + str(count)+'.wav', vocals_y, SR)\n",
    "    \n",
    "#     # for i in range(0, mixture_chroma.shape[0]-chunk_length+1,chunk_length):\n",
    "#     #     vocal_chunk = vocals_chroma[i:i+chunk_length,:]\n",
    "#     #     print(vocal_chunk.shape)\\\n",
    "#         # torch.save(vocal_chunk, out_location + 'chunks_vocal/vocal_' + str(count) + '_' + str(i//chunk_length) + '.pt')\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelChordDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_location = \"../../../../Music Technology/Datasets/musdb18hq/chunks_vocal/\",\n",
    "            out_location = \"../../../../Music Technology/Datasets/musdb18hq/chunks_chord/\",\n",
    "            frames_per_chord = 6\n",
    "        ):\n",
    "        super(MelChordDataset).__init__()\n",
    "        self.frames_per_chord = frames_per_chord\n",
    "        vocals_y = []\n",
    "        vocals_chroma = []\n",
    "        chord_templates:dict = json.load(open('./chord_templates.json'))\n",
    "        act_chord_data = []\n",
    "\n",
    "        for i in range(len(os.listdir(data_location))): # 100\n",
    "            with open(out_location+\"chord_\"+str(i), \"rb\") as fp:\n",
    "                chord_data = pickle.load(fp)\n",
    "            act_chord_data.append(torch.Tensor(np.array([np.array(chord_templates[i]) for i in chord_data])))\n",
    "            vocals_y.append(librosa.load(data_location + 'vocal_'+str(i)+'.wav', sr=SR)[0])\n",
    "            vocals_chroma.append(torch.Tensor(librosa.feature.chroma_cens(y=vocals_y[-1], sr = SR, hop_length=HOP)).T)\n",
    "        \n",
    "        # act_chord_data[i]: Shape: (num_chords[i], 12)\n",
    "        # vocals_chroma[i]: Shape: (num_frames[i], 12)\n",
    "        # num_chords[i] = (num_frames[i] // frames_per_chord)\n",
    "\n",
    "        self.data = []\n",
    "        self._create_data(act_chord_data, vocals_chroma)\n",
    "    \n",
    "    def _create_data(self, chord_data, chroma_data):\n",
    "        for (chroma, chords) in zip(chroma_data, chord_data):\n",
    "            for i in range(0, chroma.shape[0]-self.frames_per_chord, self.frames_per_chord):\n",
    "                block_chroma = chroma[i:i+self.frames_per_chord,:]\n",
    "                block_chord = chords[i//self.frames_per_chord]\n",
    "                if(block_chroma.any()):\n",
    "                    self.data.append((block_chroma, block_chord))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MelChordDataset()\n",
    "test_data = MelChordDataset(\n",
    "    data_location=\"../../../../Music Technology/Datasets/musdb18hq/chunks_vocal_test/\",\n",
    "    out_location=\"../../../../Music Technology/Datasets/musdb18hq/chunks_chord_test/\"\n",
    ")\n",
    "torch.save(train_data, './data/final/train_data.pt')\n",
    "torch.save(test_data, './data/final/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576514\n",
      "297423\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6942a376fbccce4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T20:43:41.195866Z",
     "start_time": "2023-11-19T20:43:41.189122Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size = 12, hidden_size = 64, num_layers = 1, num_classes = 12, bidirectional = True) -> None:\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first = True, bidirectional=bidirectional)\n",
    "        if(bidirectional):\n",
    "            self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(self.bidirectional):\n",
    "            h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size)\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:,-1,:] # Since we only want the output of the last cell\n",
    "        out = self.fc(out)\n",
    "        return(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cc5f87a1e87b7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T02:31:28.156497Z",
     "start_time": "2023-11-20T02:31:28.152351Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.f_dim = 19\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(12, 24, 5, 2)\n",
    "        self.conv2 = nn.Conv1d(24, 48, 5, 2)\n",
    "        self.conv3 = nn.Conv1d(48, 12, 5, 2)\n",
    "        self.FC = nn.Linear(self.f_dim * 12, 24)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.conv1(x))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        flat = torch.flatten(h3, 1)\n",
    "        h4 = self.FC(flat)\n",
    "        return self.softmax(h4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5448474f43554d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T02:32:37.199280Z",
     "start_time": "2023-11-20T02:32:37.196851Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def truth_label_to_int(gt):\n",
    "    template = json.load(open('./chord_templates.json'))\n",
    "    int_gt = torch.zeros(len(gt))\n",
    "    for i in range(len(gt)):\n",
    "        idx = list(template.keys()).index(gt[i])\n",
    "        int_gt[i] = idx\n",
    "    return int_gt.long()\n",
    "    \n",
    "def train():\n",
    "    dataset = Musdb18Dataset('../../Datasets/musdb18-wav')\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=8,\n",
    "                                               shuffle=True)\n",
    "    pred = Predictor()\n",
    "    adam = torch.optim.Adam(pred.parameters(), lr=0.0001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        epoch_loss = 0\n",
    "        count = 0\n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            ground_truth = truth_label_to_int(y)\n",
    "            out = pred(X)\n",
    "            loss = loss_fn(out, ground_truth)\n",
    "            loss.backward()\n",
    "            adam.step()\n",
    "            adam.zero_grad()\n",
    "            epoch_loss += loss.detach()\n",
    "            count += 1\n",
    "            print(loss.detach())\n",
    "        print(epoch_loss / count)\n",
    "        \n",
    "    torch.save(pred.state_dict(), 'models/predictor.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea1d2ee003e92b90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T02:33:17.229707Z",
     "start_time": "2023-11-20T02:32:37.537150Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/fg92p7r56cd82gxyhj7r9s140000gn/T/ipykernel_24541/790191051.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(h4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1787)\n",
      "tensor(3.1783)\n",
      "tensor(3.1783)\n",
      "tensor(3.1782)\n",
      "tensor(3.1793)\n",
      "tensor(3.1782)\n",
      "tensor(3.1780)\n",
      "tensor(3.1789)\n",
      "tensor(3.1784)\n",
      "tensor(3.1782)\n",
      "tensor(3.1790)\n",
      "tensor(3.1774)\n",
      "tensor(3.1791)\n",
      "tensor(3.1780)\n",
      "tensor(3.1787)\n",
      "tensor(3.1785)\n",
      "tensor(3.1775)\n",
      "tensor(3.1788)\n",
      "tensor(3.1779)\n",
      "tensor(3.1780)\n",
      "tensor(3.1784)\n",
      "tensor(3.1776)\n",
      "tensor(3.1784)\n",
      "tensor(3.1796)\n",
      "tensor(3.1781)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[74], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     22\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m truth_label_to_int(y)\n\u001b[1;32m     23\u001b[0m     out \u001b[38;5;241m=\u001b[39m pred(X)\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[66], line 17\u001b[0m, in \u001b[0;36mMusdb18Dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m other_y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/chunks_other/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mother_files[index], sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22050\u001b[39m)\n\u001b[1;32m     15\u001b[0m vocals_y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/chunks_vocal/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocal_files[index], sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22050\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m other_chroma \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchroma_cens\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m vocals_chroma \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mchroma_cens(y\u001b[38;5;241m=\u001b[39mvocals_y, sr \u001b[38;5;241m=\u001b[39m sr, hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     20\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m chroma_predict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchroma_gru, other_y)\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/feature/spectral.py:1522\u001b[0m, in \u001b[0;36mchroma_cens\u001b[0;34m(y, sr, C, hop_length, fmin, tuning, n_chroma, n_octaves, bins_per_octave, cqt_mode, window, norm, win_len_smooth, smoothing_window)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m   1515\u001b[0m     (win_len_smooth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(win_len_smooth, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger)) \u001b[38;5;129;01mand\u001b[39;00m win_len_smooth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1517\u001b[0m ):\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin_len_smooth=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwin_len_smooth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a positive integer or None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1520\u001b[0m     )\n\u001b[0;32m-> 1522\u001b[0m chroma \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_cqt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins_per_octave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins_per_octave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtuning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_chroma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_chroma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_octaves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_octaves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcqt_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcqt_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# L1-Normalization\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m chroma \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mnormalize(chroma, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/feature/spectral.py:1386\u001b[0m, in \u001b[0;36mchroma_cqt\u001b[0;34m(y, sr, C, hop_length, fmin, norm, threshold, tuning, n_chroma, n_octaves, window, bins_per_octave, cqt_mode)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[1;32m   1383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of C or y must be provided to compute chroma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m         )\n\u001b[1;32m   1385\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[0;32m-> 1386\u001b[0m         \u001b[43mcqt_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcqt_mode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m            \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_octaves\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbins_per_octave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbins_per_octave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins_per_octave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtuning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1395\u001b[0m     )\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;66;03m# Map to chroma\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m cq_to_chr \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mcq_to_chroma(\n\u001b[1;32m   1399\u001b[0m     C\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m   1400\u001b[0m     bins_per_octave\u001b[38;5;241m=\u001b[39mbins_per_octave,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[1;32m   1404\u001b[0m )\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/constantq.py:171\u001b[0m, in \u001b[0;36mcqt\u001b[0;34m(y, sr, hop_length, fmin, n_bins, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the constant-Q transform of an audio signal.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mThis implementation is based on the recursive sub-sampling method\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m       [5.147e-02, 6.959e-02, ..., 1.694e-05, 5.811e-06]])\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# CQT is the special case of VQT with gamma=0\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvqt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintervals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mequal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins_per_octave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins_per_octave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtuning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparsity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/constantq.py:1018\u001b[0m, in \u001b[0;36mvqt\u001b[0;34m(y, sr, hop_length, fmin, n_bins, intervals, gamma, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001b[0m\n\u001b[1;32m   1014\u001b[0m fft_basis[:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(sr \u001b[38;5;241m/\u001b[39m my_sr)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# Compute the vqt filter response and append to the stack\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m vqt_resp\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m-> 1018\u001b[0m     \u001b[43m__cqt_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_hop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfft_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_hop \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1022\u001b[0m     my_hop \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/constantq.py:1126\u001b[0m, in \u001b[0;36m__cqt_response\u001b[0;34m(y, n_fft, hop_length, fft_basis, mode, window, phase, dtype)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the filter response with a target STFT hop.\"\"\"\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# Compute the STFT matrix\u001b[39;00m\n\u001b[0;32m-> 1126\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m phase:\n\u001b[1;32m   1131\u001b[0m     D \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(D)\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/spectrum.py:378\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], n_columns):\n\u001b[1;32m    376\u001b[0m     bl_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(bl_s \u001b[38;5;241m+\u001b[39m n_columns, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 378\u001b[0m     stft_matrix[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, bl_s \u001b[38;5;241m+\u001b[39m off_start : bl_t \u001b[38;5;241m+\u001b[39m off_start] \u001b[38;5;241m=\u001b[39m \u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfft_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbl_s\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbl_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mrfft\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:409\u001b[0m, in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    407\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m    408\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[0;32m--> 409\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Research/venv/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:73\u001b[0m, in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     a \u001b[38;5;241m=\u001b[39m swapaxes(a, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mpfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     r \u001b[38;5;241m=\u001b[39m swapaxes(r, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa691b0b64b1707",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
