{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:36:01.263591Z",
     "start_time": "2023-11-19T20:35:59.094962Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# !!! Code in this cell is for chunking the dataset into little bits - you'll only need to run this once\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "data_location = \"../../Datasets/musdb18-wav/train/\"\n",
    "out_location = \"../../Datasets/musdb18-wav/\"\n",
    "folders = os.listdir(data_location)\n",
    "\n",
    "for folder in folders:\n",
    "    other_y, _ = librosa.load(data_location + '/' + folder + '/other.wav', sr=22050)\n",
    "    vocals_y, _ = librosa.load(data_location + '/' + folder + '/vocals.wav', sr=22050)\n",
    "    chunk_length = 22050 * 2\n",
    "    nchunks = int(other_y.shape[0] / chunk_length)\n",
    "\n",
    "    # Path(data_location + folder + '/chunks').mkdir(exist_ok=True)\n",
    "    for chunk in range(nchunks):\n",
    "        other_chunk = other_y[chunk * chunk_length:(chunk * chunk_length) + chunk_length]\n",
    "        vocal_chunk = vocals_y[chunk * chunk_length:(chunk * chunk_length) + chunk_length]\n",
    "        sf.write(out_location + 'chunks_other/chunked_other_' + folder + '_' + str(chunk) + '.wav', other_chunk, 22050)\n",
    "        sf.write(out_location + 'chunks_vocal/chunked_vocal_' + folder + '_' + str(chunk) + '.wav', vocal_chunk, 22050)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:10:53.062313Z",
     "start_time": "2023-11-01T19:10:09.625541Z"
    }
   },
   "id": "ba0e9c51f9cdef1a"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def chroma_predict(model, audio, chroma_req = True, chord_templates:dict = json.load(open('./chord_templates.json')), sr = 44100, hop = 256):\n",
    "    if chroma_req:\n",
    "        chroma = torch.Tensor(librosa.feature.chroma_cens(y=audio, sr = sr, hop_length=hop)).T.unsqueeze(0)\n",
    "    else:\n",
    "        chroma = audio\n",
    "    with torch.no_grad():\n",
    "        outputs = nn.functional.softmax(model(chroma), 1)[0]\n",
    "    min_val = 120\n",
    "    min_key = ''\n",
    "    for key, val in chord_templates.items():\n",
    "        out = torch.norm(torch.Tensor(val) - outputs)\n",
    "        if min_val >= out:\n",
    "            min_val = out\n",
    "            min_key = key\n",
    "    return min_key\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:43:39.879633Z",
     "start_time": "2023-11-19T20:43:39.873088Z"
    }
   },
   "id": "217e82dccf572040"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size = 12, hidden_size = 256, num_layers = 2, num_classes = 12, bidirectional = True) -> None:\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first = True, bidirectional=bidirectional)\n",
    "        if(bidirectional):\n",
    "            self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(self.bidirectional):\n",
    "            h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size)\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:,-1,:] # Since we only want the output of the last cell\n",
    "        out = self.fc(out)\n",
    "        return(out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T02:48:04.027161Z",
     "start_time": "2023-11-20T02:48:04.022353Z"
    }
   },
   "id": "6942a376fbccce4a"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "class Musdb18Dataset(Dataset):\n",
    "    def __init__(self, data_location):\n",
    "        super().__init__()\n",
    "        self.path = data_location\n",
    "        self.vocal_files = os.listdir(data_location + '/chunks_vocal')\n",
    "        self.other_files = os.listdir(data_location + '/chunks_other')\n",
    "        self.chroma_gru = GRU()\n",
    "        self.chroma_gru.load_state_dict(torch.load('models/chord_detector.pth'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vocal_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        other_y, sr = librosa.load(self.path + '/chunks_other/' + self.other_files[index], sr=22050)\n",
    "        vocals_y, sr = librosa.load(self.path + '/chunks_vocal/' + self.vocal_files[index], sr=22050)\n",
    "        \n",
    "        other_chroma = librosa.feature.chroma_cens(y=other_y, sr = sr, hop_length=256)\n",
    "        vocals_chroma = librosa.feature.chroma_cens(y=vocals_y, sr = sr, hop_length=256)\n",
    "        \n",
    "        ground_truth = chroma_predict(self.chroma_gru, other_y)\n",
    "        return torch.tensor(vocals_chroma), ground_truth"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T02:47:49.262619Z",
     "start_time": "2023-11-20T02:47:49.258636Z"
    }
   },
   "id": "b7ee83a91370f306"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.f_dim = 8\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(12, 24, 3, 1)\n",
    "        self.conv2 = nn.Conv1d(24, 48, 3, 1)\n",
    "        self.conv3 = nn.Conv1d(48, 96, 2, 1)\n",
    "        self.FC = nn.Linear(self.f_dim * 12, 24)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.conv1(x))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        flat = torch.flatten(h3, 1)\n",
    "        h4 = self.FC(flat)\n",
    "        return self.softmax(h4) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T19:45:57.732667Z",
     "start_time": "2023-11-20T19:45:57.728831Z"
    }
   },
   "id": "1cc5f87a1e87b7a"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def truth_label_to_int(gt):\n",
    "    template = json.load(open('./chord_templates.json'))\n",
    "    int_gt = torch.zeros(len(gt))\n",
    "    for i in range(len(gt)):\n",
    "        idx = list(template.keys()).index(gt[i])\n",
    "        int_gt[i] = idx\n",
    "    return int_gt.long()\n",
    "    \n",
    "def train():\n",
    "    dataset = Musdb18Dataset('../../Datasets/musdb18-wav')\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=8,\n",
    "                                               shuffle=True)\n",
    "    pred = Predictor()\n",
    "    adam = torch.optim.Adam(pred.parameters(), lr=0.0001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        epoch_loss = 0\n",
    "        count = 0\n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            ground_truth = truth_label_to_int(y)\n",
    "            out = pred(X)\n",
    "            loss = loss_fn(out, ground_truth)\n",
    "            loss.backward()\n",
    "            adam.step()\n",
    "            adam.zero_grad()\n",
    "            epoch_loss += loss.detach()\n",
    "            count += 1\n",
    "        print(epoch_loss / count)\n",
    "        \n",
    "    torch.save(pred.state_dict(), 'models/predictor.model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T02:48:32.957586Z",
     "start_time": "2023-11-20T02:48:32.955288Z"
    }
   },
   "id": "f5448474f43554d9"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/fg92p7r56cd82gxyhj7r9s140000gn/T/ipykernel_24541/790191051.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(h4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1462)\n",
      "tensor(3.1351)\n",
      "tensor(3.1345)\n",
      "tensor(3.1344)\n",
      "tensor(3.1342)\n",
      "tensor(3.1338)\n",
      "tensor(3.1338)\n",
      "tensor(3.1333)\n",
      "tensor(3.1333)\n",
      "tensor(3.1331)\n",
      "tensor(3.1329)\n",
      "tensor(3.1325)\n",
      "tensor(3.1321)\n",
      "tensor(3.1314)\n",
      "tensor(3.1312)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3154\u001B[0m, in \u001B[0;36mndim\u001B[0;34m(a)\u001B[0m\n\u001B[1;32m   3153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\n\u001B[1;32m   3155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'ndim'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[93], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[92], line 21\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     20\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (X, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[1;32m     22\u001B[0m     ground_truth \u001B[38;5;241m=\u001B[39m truth_label_to_int(y)\n\u001B[1;32m     23\u001B[0m     out \u001B[38;5;241m=\u001B[39m pred(X)\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[0;32mIn[85], line 20\u001B[0m, in \u001B[0;36mMusdb18Dataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     17\u001B[0m other_chroma \u001B[38;5;241m=\u001B[39m librosa\u001B[38;5;241m.\u001B[39mfeature\u001B[38;5;241m.\u001B[39mchroma_cens(y\u001B[38;5;241m=\u001B[39mother_y, sr \u001B[38;5;241m=\u001B[39m sr, hop_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m)\n\u001B[1;32m     18\u001B[0m vocals_chroma \u001B[38;5;241m=\u001B[39m librosa\u001B[38;5;241m.\u001B[39mfeature\u001B[38;5;241m.\u001B[39mchroma_cens(y\u001B[38;5;241m=\u001B[39mvocals_y, sr \u001B[38;5;241m=\u001B[39m sr, hop_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m ground_truth \u001B[38;5;241m=\u001B[39m \u001B[43mchroma_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchroma_gru\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(vocals_chroma), ground_truth\n",
      "Cell \u001B[0;32mIn[31], line 3\u001B[0m, in \u001B[0;36mchroma_predict\u001B[0;34m(model, audio, chroma_req, chord_templates, sr, hop)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchroma_predict\u001B[39m(model, audio, chroma_req \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, chord_templates:\u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./chord_templates.json\u001B[39m\u001B[38;5;124m'\u001B[39m)), sr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m44100\u001B[39m, hop \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m256\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chroma_req:\n\u001B[0;32m----> 3\u001B[0m         chroma \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor(\u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchroma_cens\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhop\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m         chroma \u001B[38;5;241m=\u001B[39m audio\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/feature/spectral.py:1522\u001B[0m, in \u001B[0;36mchroma_cens\u001B[0;34m(y, sr, C, hop_length, fmin, tuning, n_chroma, n_octaves, bins_per_octave, cqt_mode, window, norm, win_len_smooth, smoothing_window)\u001B[0m\n\u001B[1;32m   1514\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m   1515\u001B[0m     (win_len_smooth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(win_len_smooth, (\u001B[38;5;28mint\u001B[39m, np\u001B[38;5;241m.\u001B[39minteger)) \u001B[38;5;129;01mand\u001B[39;00m win_len_smooth \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m   1517\u001B[0m ):\n\u001B[1;32m   1518\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ParameterError(\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwin_len_smooth=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwin_len_smooth\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be a positive integer or None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1520\u001B[0m     )\n\u001B[0;32m-> 1522\u001B[0m chroma \u001B[38;5;241m=\u001B[39m \u001B[43mchroma_cqt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1523\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1525\u001B[0m \u001B[43m    \u001B[49m\u001B[43msr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1526\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhop_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1527\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1528\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbins_per_octave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbins_per_octave\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtuning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtuning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_chroma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_chroma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_octaves\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_octaves\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcqt_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcqt_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1534\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1535\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# L1-Normalization\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m chroma \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mnormalize(chroma, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/feature/spectral.py:1386\u001B[0m, in \u001B[0;36mchroma_cqt\u001B[0;34m(y, sr, C, hop_length, fmin, norm, threshold, tuning, n_chroma, n_octaves, window, bins_per_octave, cqt_mode)\u001B[0m\n\u001B[1;32m   1381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1382\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ParameterError(\n\u001B[1;32m   1383\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAt least one of C or y must be provided to compute chroma\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1384\u001B[0m         )\n\u001B[1;32m   1385\u001B[0m     C \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mabs(\n\u001B[0;32m-> 1386\u001B[0m         \u001B[43mcqt_func\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcqt_mode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1387\u001B[0m \u001B[43m            \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1388\u001B[0m \u001B[43m            \u001B[49m\u001B[43msr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1389\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhop_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1390\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_bins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_octaves\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbins_per_octave\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1392\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbins_per_octave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbins_per_octave\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1393\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtuning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtuning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1394\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1395\u001B[0m     )\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;66;03m# Map to chroma\u001B[39;00m\n\u001B[1;32m   1398\u001B[0m cq_to_chr \u001B[38;5;241m=\u001B[39m filters\u001B[38;5;241m.\u001B[39mcq_to_chroma(\n\u001B[1;32m   1399\u001B[0m     C\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m],\n\u001B[1;32m   1400\u001B[0m     bins_per_octave\u001B[38;5;241m=\u001B[39mbins_per_octave,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1403\u001B[0m     window\u001B[38;5;241m=\u001B[39mwindow,\n\u001B[1;32m   1404\u001B[0m )\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/constantq.py:171\u001B[0m, in \u001B[0;36mcqt\u001B[0;34m(y, sr, hop_length, fmin, n_bins, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute the constant-Q transform of an audio signal.\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \n\u001B[1;32m     48\u001B[0m \u001B[38;5;124;03mThis implementation is based on the recursive sub-sampling method\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m       [5.147e-02, 6.959e-02, ..., 1.694e-05, 5.811e-06]])\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# CQT is the special case of VQT with gamma=0\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvqt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[43msr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhop_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_bins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_bins\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintervals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mequal\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbins_per_octave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbins_per_octave\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtuning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtuning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilter_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilter_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43msparsity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msparsity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43mres_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mres_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/constantq.py:1001\u001B[0m, in \u001B[0;36mvqt\u001B[0;34m(y, sr, hop_length, fmin, n_bins, intervals, gamma, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001B[0m\n\u001B[1;32m    998\u001B[0m freqs_oct \u001B[38;5;241m=\u001B[39m freqs[sl]\n\u001B[1;32m    999\u001B[0m alpha_oct \u001B[38;5;241m=\u001B[39m alpha[sl]\n\u001B[0;32m-> 1001\u001B[0m fft_basis, n_fft, _ \u001B[38;5;241m=\u001B[39m \u001B[43m__vqt_filter_fft\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1002\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmy_sr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfreqs_oct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1004\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilter_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1005\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1006\u001B[0m \u001B[43m    \u001B[49m\u001B[43msparsity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1007\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1008\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1009\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1010\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_oct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1011\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;66;03m# Re-scale the filters to compensate for downsampling\u001B[39;00m\n\u001B[1;32m   1014\u001B[0m fft_basis[:] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(sr \u001B[38;5;241m/\u001B[39m my_sr)\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/core/constantq.py:1088\u001B[0m, in \u001B[0;36m__vqt_filter_fft\u001B[0;34m(sr, freqs, filter_scale, norm, sparsity, hop_length, window, gamma, dtype, alpha)\u001B[0m\n\u001B[1;32m   1085\u001B[0m fft_basis \u001B[38;5;241m=\u001B[39m fft\u001B[38;5;241m.\u001B[39mfft(basis, n\u001B[38;5;241m=\u001B[39mn_fft, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[:, : (n_fft \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   1087\u001B[0m \u001B[38;5;66;03m# sparsify the basis\u001B[39;00m\n\u001B[0;32m-> 1088\u001B[0m fft_basis \u001B[38;5;241m=\u001B[39m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparsify_rows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfft_basis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquantile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msparsity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fft_basis, n_fft, lengths\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/librosa/util/utils.py:1466\u001B[0m, in \u001B[0;36msparsify_rows\u001B[0;34m(x, quantile, dtype)\u001B[0m\n\u001B[1;32m   1464\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(threshold_idx):\n\u001B[1;32m   1465\u001B[0m     idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(mags[i] \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m mag_sort[i, j])\n\u001B[0;32m-> 1466\u001B[0m     \u001B[43mx_sparse\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m x[i, idx]\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x_sparse\u001B[38;5;241m.\u001B[39mtocsr()\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/scipy/sparse/_lil.py:331\u001B[0m, in \u001B[0;36mlil_matrix.__setitem__\u001B[0;34m(self, key, x)\u001B[0m\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_intXint(key[\u001B[38;5;241m0\u001B[39m], key[\u001B[38;5;241m1\u001B[39m], x)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;66;03m# Everything else takes the normal path.\u001B[39;00m\n\u001B[0;32m--> 331\u001B[0m \u001B[43mIndexMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__setitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/scipy/sparse/_index.py:97\u001B[0m, in \u001B[0;36mIndexMixin.__setitem__\u001B[0;34m(self, key, x)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__setitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, x):\n\u001B[0;32m---> 97\u001B[0m     row, col \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row, INT_TYPES) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, INT_TYPES):\n\u001B[1;32m    100\u001B[0m         x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype)\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/scipy/sparse/_index.py:161\u001B[0m, in \u001B[0;36mIndexMixin._validate_indices\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row, \u001B[38;5;28mslice\u001B[39m):\n\u001B[1;32m    159\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_asindices(row, M)\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43misintlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    162\u001B[0m     col \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(col)\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m-\u001B[39mN \u001B[38;5;129;01mor\u001B[39;00m col \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m N:\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/scipy/sparse/_sputils.py:222\u001B[0m, in \u001B[0;36misintlike\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Is x appropriate as an index into a sparse matrix? Returns True\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03mif it can be cast safely to a machine int.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;66;03m# Fast-path check to eliminate non-scalar values. operator.index would\u001B[39;00m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;66;03m# catch this case too, but the exception catching is slow.\u001B[39;00m\n\u001B[0;32m--> 222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mndim\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Research/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3154\u001B[0m, in \u001B[0;36mndim\u001B[0;34m(a)\u001B[0m\n\u001B[1;32m   3123\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3124\u001B[0m \u001B[38;5;124;03mReturn the number of dimensions of an array.\u001B[39;00m\n\u001B[1;32m   3125\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3151\u001B[0m \n\u001B[1;32m   3152\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\n\u001B[1;32m   3155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[1;32m   3156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m asarray(a)\u001B[38;5;241m.\u001B[39mndim\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:33:01.274552Z",
     "start_time": "2023-11-20T02:48:33.195207Z"
    }
   },
   "id": "ea1d2ee003e92b90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f42c5e9051c14a49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
